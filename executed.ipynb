{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f14a8128",
   "metadata": {},
   "source": [
    "# Indian Temple Travel Chatbot Setup, Data, Embeddings\n",
    "First part: install dependencies, load/preprocess the dataset, build embeddings, and run sample retrievals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d9a7ead",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T16:27:16.528365Z",
     "iopub.status.busy": "2025-11-30T16:27:16.528038Z",
     "iopub.status.idle": "2025-11-30T16:27:19.047117Z",
     "shell.execute_reply": "2025-11-30T16:27:19.046250Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastapi in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.122.0)\n",
      "Requirement already satisfied: uvicorn in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.38.0)\n",
      "Requirement already satisfied: streamlit in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.51.0)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (5.1.2)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.13.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.57.3)\n",
      "Requirement already satisfied: langchain in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.3.5)\n",
      "Requirement already satisfied: starlette<0.51.0,>=0.40.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from fastapi) (0.50.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from fastapi) (2.12.5)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from fastapi) (4.15.0)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from fastapi) (0.0.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.2)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from starlette<0.51.0,>=0.40.0->fastapi) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.51.0,>=0.40.0->fastapi) (3.11)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.51.0,>=0.40.0->fastapi) (1.3.1)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from uvicorn) (8.3.1)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from uvicorn) (0.16.0)\n",
      "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<7,>=4.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (6.2.2)\n",
      "Requirement already satisfied: packaging<26,>=20 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (25.0)\n",
      "Requirement already satisfied: pillow<13,>=7.1.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (12.0.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (6.33.1)\n",
      "Requirement already satisfied: pyarrow<22,>=7.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (21.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (2.32.5)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (9.1.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (3.1.45)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in c:\\users\\prana\\appdata\\roaming\\python\\python313\\site-packages (from streamlit) (6.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\prana\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.12.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from click>=7.0->uvicorn) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2025.11.12)\n",
      "Requirement already satisfied: tqdm in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (2.9.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (1.7.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (1.16.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (0.36.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.10.0)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.1.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain) (1.1.0)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain) (1.0.4)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (0.4.49)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.0->langchain) (3.0.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.10)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (0.25.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.29.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\prana\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# 1) Install all dependencies\n",
    "!pip install fastapi uvicorn streamlit sentence-transformers faiss-cpu transformers langchain pandas numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d58abb8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T16:27:19.050098Z",
     "iopub.status.busy": "2025-11-30T16:27:19.049799Z",
     "iopub.status.idle": "2025-11-30T16:27:28.656881Z",
     "shell.execute_reply": "2025-11-30T16:27:28.655516Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2) Imports + constants\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "DATA_PATH = \"combined_temple_dataset_for_chatbot.json\"\n",
    "EMBED_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "TOP_K = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8570cefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from chatbot_backend import TempleChatbot, search_temples\n",
    "from app import load_chatbot_resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fdd8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from chatbot_backend import TempleChatbot, search_temples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fdd685e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T16:27:28.662042Z",
     "iopub.status.busy": "2025-11-30T16:27:28.661027Z",
     "iopub.status.idle": "2025-11-30T16:27:28.711646Z",
     "shell.execute_reply": "2025-11-30T16:27:28.710714Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total temples loaded: 365\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>state</th>\n",
       "      <th>location</th>\n",
       "      <th>deities</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>text</th>\n",
       "      <th>raw</th>\n",
       "      <th>search_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>temple_adi_keshava_temple_bhubaneswar_odisha</td>\n",
       "      <td>Adi Keshava Temple, Bhubaneswar</td>\n",
       "      <td>Odisha</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Adi Keshava Temple, Bhubaneswar | Odisha</td>\n",
       "      <td>{'id': 'temple_adi_keshava_temple_bhubaneswar_...</td>\n",
       "      <td>Adi Keshava Temple, Bhubaneswar | Odisha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>temple_agatti_devi_temple_agatti_lakshadweep_l...</td>\n",
       "      <td>Agatti Devi Temple, Agatti, Lakshadweep</td>\n",
       "      <td>Lakshadweep</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Agatti Devi Temple, Agatti, Lakshadweep | Laks...</td>\n",
       "      <td>{'id': 'temple_agatti_devi_temple_agatti_laksh...</td>\n",
       "      <td>Agatti Devi Temple, Agatti, Lakshadweep | Laks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>temple_akshardham_temple_delhi</td>\n",
       "      <td>Akshardham Temple</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Akshardham Temple | Delhi</td>\n",
       "      <td>{'id': 'temple_akshardham_temple_delhi', 'cate...</td>\n",
       "      <td>Akshardham Temple | Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>temple_akshardham_temple_gujarat</td>\n",
       "      <td>Akshardham Temple</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>Gandhinagar</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Akshardham Temple | Gujarat</td>\n",
       "      <td>{'id': 'temple_akshardham_temple_gujarat', 'ca...</td>\n",
       "      <td>Akshardham Temple | Gujarat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>temple_akshardham_temple_new_delhi_delhi_uttar...</td>\n",
       "      <td>Akshardham Temple, New Delhi, Delhi</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Akshardham Temple, New Delhi, Delhi | Uttar Pr...</td>\n",
       "      <td>{'id': 'temple_akshardham_temple_new_delhi_del...</td>\n",
       "      <td>Akshardham Temple, New Delhi, Delhi | Uttar Pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  \\\n",
       "0       temple_adi_keshava_temple_bhubaneswar_odisha   \n",
       "1  temple_agatti_devi_temple_agatti_lakshadweep_l...   \n",
       "2                     temple_akshardham_temple_delhi   \n",
       "3                   temple_akshardham_temple_gujarat   \n",
       "4  temple_akshardham_temple_new_delhi_delhi_uttar...   \n",
       "\n",
       "                                      name          state     location  \\\n",
       "0          Adi Keshava Temple, Bhubaneswar         Odisha                \n",
       "1  Agatti Devi Temple, Agatti, Lakshadweep    Lakshadweep                \n",
       "2                        Akshardham Temple          Delhi    New Delhi   \n",
       "3                        Akshardham Temple        Gujarat  Gandhinagar   \n",
       "4      Akshardham Temple, New Delhi, Delhi  Uttar Pradesh                \n",
       "\n",
       "  deities   lat   lng                                               text  \\\n",
       "0      []  None  None           Adi Keshava Temple, Bhubaneswar | Odisha   \n",
       "1      []  None  None  Agatti Devi Temple, Agatti, Lakshadweep | Laks...   \n",
       "2      []  None  None                          Akshardham Temple | Delhi   \n",
       "3      []  None  None                        Akshardham Temple | Gujarat   \n",
       "4      []  None  None  Akshardham Temple, New Delhi, Delhi | Uttar Pr...   \n",
       "\n",
       "                                                 raw  \\\n",
       "0  {'id': 'temple_adi_keshava_temple_bhubaneswar_...   \n",
       "1  {'id': 'temple_agatti_devi_temple_agatti_laksh...   \n",
       "2  {'id': 'temple_akshardham_temple_delhi', 'cate...   \n",
       "3  {'id': 'temple_akshardham_temple_gujarat', 'ca...   \n",
       "4  {'id': 'temple_akshardham_temple_new_delhi_del...   \n",
       "\n",
       "                                         search_text  \n",
       "0           Adi Keshava Temple, Bhubaneswar | Odisha  \n",
       "1  Agatti Devi Temple, Agatti, Lakshadweep | Laks...  \n",
       "2                          Akshardham Temple | Delhi  \n",
       "3                        Akshardham Temple | Gujarat  \n",
       "4  Akshardham Temple, New Delhi, Delhi | Uttar Pr...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample search text:\n",
      " Adi Keshava Temple, Bhubaneswar | Odisha\n"
     ]
    }
   ],
   "source": [
    "# 3) Data Loading & Preprocessing\n",
    "def load_raw_data(path: str) -> List[Dict[str, Any]]:\n",
    "    path_obj = Path(path)\n",
    "    if not path_obj.exists():\n",
    "        raise FileNotFoundError(f\"Dataset not found at {path_obj.resolve()}\")\n",
    "    with path_obj.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    if isinstance(data, dict) and \"data\" in data:\n",
    "        data = data[\"data\"]\n",
    "    if not isinstance(data, list):\n",
    "        raise ValueError(\"Expected top-level JSON array of temple records.\")\n",
    "    return data\n",
    "\n",
    "TEXT_FIELDS = [\n",
    "    \"overview\",\n",
    "    \"story\",\n",
    "    \"visiting_guide\",\n",
    "    \"architecture\",\n",
    "    \"scripture_mentions\",\n",
    "]\n",
    "\n",
    "def to_list(value: Any) -> List[str]:\n",
    "    if value is None:\n",
    "        return []\n",
    "    if isinstance(value, list):\n",
    "        return [str(v).strip() for v in value if str(v).strip()]\n",
    "    if isinstance(value, str):\n",
    "        parts = [p.strip() for p in value.replace(\";\", \",\").split(\",\") if p.strip()]\n",
    "        return parts or [value.strip()]\n",
    "    return [str(value).strip()]\n",
    "\n",
    "def build_search_text(item: Dict[str, Any]) -> str:\n",
    "    parts: List[str] = []\n",
    "    name = (item.get(\"name\") or item.get(\"temple_name\") or \"\").strip()\n",
    "    state = (item.get(\"state\") or item.get(\"region\") or \"\").strip()\n",
    "    deities = to_list(item.get(\"deities\") or item.get(\"deity\"))\n",
    "    base_values = [name, state, \", \".join(deities)]\n",
    "    for val in base_values:\n",
    "        if val:\n",
    "            parts.append(val)\n",
    "    for field in TEXT_FIELDS:\n",
    "        val = item.get(field)\n",
    "        if val is None:\n",
    "            continue\n",
    "        if isinstance(val, list):\n",
    "            val = \" \".join(str(v).strip() for v in val if str(v).strip())\n",
    "        else:\n",
    "            val = str(val).strip()\n",
    "        if val:\n",
    "            parts.append(val)\n",
    "    return \" | \".join(parts)\n",
    "\n",
    "def normalize_record(rec: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    name = rec.get(\"name\") or rec.get(\"temple_name\") or \"\"\n",
    "    state = rec.get(\"state\") or rec.get(\"region\") or \"\"\n",
    "    location = rec.get(\"location\") or rec.get(\"city\") or rec.get(\"place\") or \"\"\n",
    "    deities = to_list(rec.get(\"deities\") or rec.get(\"deity\"))\n",
    "    lat = rec.get(\"lat\") or rec.get(\"latitude\")\n",
    "    lng = rec.get(\"lng\") or rec.get(\"longitude\")\n",
    "    search_text = build_search_text(\n",
    "        {\n",
    "            \"name\": name,\n",
    "            \"state\": state,\n",
    "            \"deities\": deities,\n",
    "            **{field: rec.get(field) for field in TEXT_FIELDS},\n",
    "        }\n",
    "    )\n",
    "    return {\n",
    "        \"id\": rec.get(\"id\") or rec.get(\"temple_id\") or rec.get(\"slug\") or name,\n",
    "        \"name\": name,\n",
    "        \"state\": state,\n",
    "        \"location\": location,\n",
    "        \"deities\": deities,\n",
    "        \"lat\": lat,\n",
    "        \"lng\": lng,\n",
    "        \"text\": search_text,\n",
    "        \"raw\": rec,\n",
    "    }\n",
    "\n",
    "raw_data = load_raw_data(DATA_PATH)\n",
    "normalized = [normalize_record(r) for r in raw_data]\n",
    "\n",
    "df = pd.DataFrame(normalized)\n",
    "df[\"search_text\"] = df[\"text\"].fillna(\"\")\n",
    "print(\"Total temples loaded:\", len(df))\n",
    "display(df.head())\n",
    "print(\"\\nSample search text:\\n\", df.loc[0, \"search_text\"][:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25e5fa09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T16:27:28.714949Z",
     "iopub.status.busy": "2025-11-30T16:27:28.714481Z",
     "iopub.status.idle": "2025-11-30T16:27:31.604277Z",
     "shell.execute_reply": "2025-11-30T16:27:31.603144Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 12/12 [00:01<00:00, 10.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (365, 384)\n",
      "FAISS index size: 365\n",
      "\n",
      "Query: Shiva temple in Tamil Nadu with rich architecture\n",
      "- Shiva Temple (Karnataka) | Deities:  | score=0.8376\n",
      "- Shiva Temple (Jammu and Kashmir) | Deities:  | score=0.7360\n",
      "- Somnath Temple, Gujarat (Shiva) | Deities: Shiva | score=0.7054\n",
      "\n",
      "Query: temple dedicated to Lord Vishnu near river\n",
      "- Tirupati Balaji Temple, Andhra Pradesh (Vishnu) | Deities: Vishnu | score=0.6690\n",
      "- Dwarkadhish Temple, Gujarat (Vishnu) | Deities: Vishnu | score=0.6610\n",
      "- Ranganathaswamy Temple, Tamil Nadu (Vishnu) | Deities: Vishnu | score=0.6475\n",
      "\n",
      "Query: famous Durga shrine in the Himalayas\n",
      "- Durga Temple (Karnataka) | Deities:  | score=0.7126\n",
      "- Durga Temple (Jammu and Kashmir) | Deities:  | score=0.6994\n",
      "- Kalighat Temple, West Bengal (Durga) | Deities: Durga | score=0.6919\n",
      "\n",
      "Example query: famous temples in Tamil Nadu (top 5)\n",
      "- Sripuram Golden Temple (Tamil Nadu) | score=0.7297\n",
      "- Srirangam Ranganathaswamy Temple, Srirangam (Tamil Nadu) | score=0.7127\n",
      "- Shore Temple (Tamil Nadu) | score=0.6984\n",
      "- Ramanathaswamy Temple (Tamil Nadu) | score=0.6899\n",
      "- Ranganathaswamy Temple (Tamil Nadu) | score=0.6863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 4) Embeddings + FAISS Index\n",
    "from functools import lru_cache\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "def get_model():\n",
    "    return SentenceTransformer(EMBED_MODEL_NAME)\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "def get_embeddings_and_index():\n",
    "    model = get_model()\n",
    "    corpus_texts = df[\"search_text\"].fillna(\"\").tolist()\n",
    "    embeddings = model.encode(\n",
    "        corpus_texts,\n",
    "        show_progress_bar=True,\n",
    "        convert_to_numpy=True,\n",
    "        normalize_embeddings=True,\n",
    "    )\n",
    "    dimension = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatIP(dimension)\n",
    "    index.add(embeddings)\n",
    "    return embeddings, index\n",
    "\n",
    "model = get_model()\n",
    "embeddings, index = get_embeddings_and_index()\n",
    "print(\"Embeddings shape:\", embeddings.shape)\n",
    "print(\"FAISS index size:\", index.ntotal)\n",
    "\n",
    "metadata = df.to_dict(orient=\"records\")\n",
    "\n",
    "def search_temples(\n",
    "    query: str,\n",
    "    k: int = TOP_K,\n",
    "    state_filter: Optional[str] = None,\n",
    "    deity_filter: Optional[str] = None,\n",
    "):\n",
    "    if not query or not query.strip():\n",
    "        return []\n",
    "    query_vec = model.encode([query], convert_to_numpy=True, normalize_embeddings=True)\n",
    "    distances, indices = index.search(query_vec, k=k * 5)\n",
    "    results = []\n",
    "    for idx, dist in zip(indices[0], distances[0]):\n",
    "        if idx == -1:\n",
    "            continue\n",
    "        rec = metadata[idx]\n",
    "        if state_filter and state_filter.lower() not in rec.get(\"state\", \"\").lower():\n",
    "            continue\n",
    "        if deity_filter:\n",
    "            deities = rec.get(\"deities\") or []\n",
    "            if not any(deity_filter.lower() in str(d).lower() for d in deities):\n",
    "                continue\n",
    "        results.append(\n",
    "            {\n",
    "                \"name\": rec.get(\"name\", \"\"),\n",
    "                \"state\": rec.get(\"state\", \"\"),\n",
    "                \"score\": float(dist),\n",
    "                \"raw\": rec,\n",
    "            }\n",
    "        )\n",
    "        if len(results) >= k:\n",
    "            break\n",
    "    return results\n",
    "\n",
    "sample_queries = [\n",
    "    \"Shiva temple in Tamil Nadu with rich architecture\",\n",
    "    \"temple dedicated to Lord Vishnu near river\",\n",
    "    \"famous Durga shrine in the Himalayas\",\n",
    "]\n",
    "\n",
    "for q in sample_queries:\n",
    "    print(f\"\\nQuery: {q}\")\n",
    "    for r in search_temples(q, k=3):\n",
    "        rec_raw = r[\"raw\"] or {}\n",
    "        deities = to_list(rec_raw.get(\"deities\") or rec_raw.get(\"deity\")) if isinstance(rec_raw, dict) else []\n",
    "        print(\n",
    "            f\"- {r['name']} ({r['state']}) | Deities: {', '.join(deities)} | score={r['score']:.4f}\"\n",
    "        )\n",
    "\n",
    "tamil_nadu_example = search_temples(\"famous temples in Tamil Nadu\", k=5, state_filter=\"Tamil Nadu\")\n",
    "print(\"\\nExample query: famous temples in Tamil Nadu (top 5)\")\n",
    "for hit in tamil_nadu_example:\n",
    "    print(f\"- {hit['name']} ({hit['state']}) | score={hit['score']:.4f}\")\n",
    "if not tamil_nadu_example:\n",
    "    print(\"No results returned for the example query.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997468a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e45e1c7b",
   "metadata": {},
   "source": [
    "# Section 2  NLU, Intents, Entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "815e7a84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T16:27:31.608800Z",
     "iopub.status.busy": "2025-11-30T16:27:31.608422Z",
     "iopub.status.idle": "2025-11-30T16:27:31.730224Z",
     "shell.execute_reply": "2025-11-30T16:27:31.729111Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent test: TEMPLE_INFO\n",
      "Entities test 1: {'temples': [], 'states': ['Tamil Nadu'], 'deities': [], 'days': 3}\n",
      "Entities test 2: {'temples': ['Shiva Temple'], 'states': ['Karnataka', 'Shiva'], 'deities': ['Shiva'], 'days': None}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5) Section 2: Intents + Entity Extraction\n",
    "import re\n",
    "\n",
    "INTENTS = [\n",
    "    \"TEMPLE_INFO\",\n",
    "    \"FIND_TEMPLES\",\n",
    "    \"PLAN_TRIP\",\n",
    "    \"ITINERARY_COST\",\n",
    "    \"SMALL_TALK\",\n",
    "    \"UNKNOWN\",\n",
    "]\n",
    "\n",
    "intent_examples = {\n",
    "    \"TEMPLE_INFO\": [\n",
    "        \"Tell me about Kedarnath temple\",\n",
    "        \"Give details on this temple\",\n",
    "        \"History of the temple\",\n",
    "        \"Temple overview\",\n",
    "    ],\n",
    "    \"FIND_TEMPLES\": [\n",
    "        \"temples in Tamil Nadu\",\n",
    "        \"find Shiva temples near river\",\n",
    "        \"list famous Vishnu shrines\",\n",
    "        \"recommend temples to visit\",\n",
    "    ],\n",
    "    \"PLAN_TRIP\": [\n",
    "        \"plan a 3 day trip\",\n",
    "        \"help me plan a pilgrimage\",\n",
    "        \"itinerary for temples\",\n",
    "        \"trip plan with timings\",\n",
    "    ],\n",
    "    \"ITINERARY_COST\": [\n",
    "        \"budget for a 2 day temple trip\",\n",
    "        \"what is the cost for visiting\",\n",
    "        \"estimate expenses for pilgrimage\",\n",
    "        \"trip cost for temples\",\n",
    "    ],\n",
    "    \"SMALL_TALK\": [\n",
    "        \"hello\",\n",
    "        \"how are you\",\n",
    "        \"thanks\",\n",
    "        \"good morning\",\n",
    "    ],\n",
    "    \"UNKNOWN\": [\n",
    "        \"random question\",\n",
    "        \"not sure\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "intent_ex_embeddings = {}\n",
    "for intent, phrases in intent_examples.items():\n",
    "    emb = model.encode(phrases, convert_to_numpy=True, normalize_embeddings=True)\n",
    "    intent_ex_embeddings[intent] = emb\n",
    "\n",
    "RULE_KEYWORDS = {\n",
    "    \"ITINERARY_COST\": [\"cost\", \"budget\", \"price\", \"expense\"],\n",
    "    \"PLAN_TRIP\": [\"plan\", \"itinerary\", \"trip\", \"travel\"],\n",
    "    \"TEMPLE_INFO\": [\"about\", \"details\", \"history\", \"information\", \"info\"],\n",
    "    \"FIND_TEMPLES\": [\"find\", \"show\", \"list\", \"recommend\", \"suggest\", \"near\"],\n",
    "    \"SMALL_TALK\": [\"hello\", \"hi\", \"thanks\", \"thank you\", \"good morning\", \"good evening\"],\n",
    "}\n",
    "\n",
    "\n",
    "def _rule_based_intent(text_lower: str):\n",
    "    for intent, keywords in RULE_KEYWORDS.items():\n",
    "        if any(kw in text_lower for kw in keywords):\n",
    "            return intent\n",
    "    return None\n",
    "\n",
    "\n",
    "def detect_intent(user_message: str) -> str:\n",
    "    \"\"\"Deterministic intent detection using rules first, embeddings fallback.\"\"\"\n",
    "    if not user_message or not user_message.strip():\n",
    "        return \"UNKNOWN\"\n",
    "    text = user_message.strip()\n",
    "    text_lower = text.lower()\n",
    "\n",
    "    rule_intent = _rule_based_intent(text_lower)\n",
    "    if rule_intent:\n",
    "        return rule_intent\n",
    "\n",
    "    q_emb = model.encode([text], convert_to_numpy=True, normalize_embeddings=True)[0]\n",
    "    best_intent, best_score = \"UNKNOWN\", -1.0\n",
    "    for intent, emb in intent_ex_embeddings.items():\n",
    "        scores = emb @ q_emb  # cosine similarity\n",
    "        top = float(scores.max())\n",
    "        if top > best_score:\n",
    "            best_intent, best_score = intent, top\n",
    "    return best_intent\n",
    "\n",
    "# Precompute vocab for entity extraction\n",
    "TEMPLE_NAMES = sorted({name for name in df[\"name\"].dropna().tolist() if name})\n",
    "STATE_NAMES = sorted({s for s in df[\"state\"].dropna().tolist() if s})\n",
    "DEITY_NAMES = sorted({d for deities in df[\"deities\"].tolist() for d in (deities or []) if d})\n",
    "\n",
    "def _find_substrings(candidates, text_lower: str, max_hits: int = 5):\n",
    "    hits = [c for c in candidates if c and c.lower() in text_lower]\n",
    "    return hits[:max_hits]\n",
    "\n",
    "\n",
    "def extract_entities(user_message: str):\n",
    "    msg_lower = user_message.lower() if user_message else \"\"\n",
    "    temples = _find_substrings(TEMPLE_NAMES, msg_lower)\n",
    "    states = _find_substrings(STATE_NAMES, msg_lower)\n",
    "    deities = _find_substrings(DEITY_NAMES, msg_lower)\n",
    "\n",
    "    day_match = re.search(r\"(\\d+)\\s*day(?:s)?\", msg_lower)\n",
    "    days = int(day_match.group(1)) if day_match else None\n",
    "\n",
    "    return {\n",
    "        \"temples\": temples,\n",
    "        \"states\": states,\n",
    "        \"deities\": deities,\n",
    "        \"days\": days,\n",
    "    }\n",
    "\n",
    "# Tests / verification\n",
    "print(\"Intent test:\", detect_intent(\"Tell me about Kedarnath temple\"))\n",
    "print(\"Entities test 1:\", extract_entities(\"Plan a 3 day trip in Tamil Nadu\"))\n",
    "print(\"Entities test 2:\", extract_entities(\"Show Shiva temples in Karnataka\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f021307",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b4b854c",
   "metadata": {},
   "source": [
    "# Section 3  Generation + Chatbot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cf4976a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T16:27:31.735517Z",
     "iopub.status.busy": "2025-11-30T16:27:31.734841Z",
     "iopub.status.idle": "2025-11-30T16:27:32.582813Z",
     "shell.execute_reply": "2025-11-30T16:27:32.581893Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPL skipped (no interactive stdin available).\n"
     ]
    }
   ],
   "source": [
    "# 6) Section 3: Local FLAN-T5 generation + Chatbot\n",
    "import textwrap\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")\n",
    "flan_model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\")\n",
    "\n",
    "\n",
    "def generate_answer(context_text: str, user_message: str, max_new_tokens: int = 180) -> str:\n",
    "    prompt = textwrap.dedent(\n",
    "        f\"\"\"\n",
    "        You are a helpful Indian temple travel assistant.\n",
    "        Use ONLY the following context to answer:\n",
    "        {context_text}\n",
    "        Question: {user_message}\n",
    "        Answer in 4-6 friendly sentences.\n",
    "        \"\"\"\n",
    "    ).strip()\n",
    "    try:\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "        outputs = flan_model.generate(**inputs, max_new_tokens=max_new_tokens, do_sample=False)\n",
    "        return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    except Exception:\n",
    "        if context_text.strip():\n",
    "            return \"Here's what I can share from what I know: \" + context_text[:400]\n",
    "        return \"I don't have enough context yet, but I can help if you mention a temple, state, or deity.\"\n",
    "\n",
    "\n",
    "class TempleChatbot:\n",
    "    def __init__(self, temples, embeddings, faiss_index, tokenizer, model):\n",
    "        self.temples = temples\n",
    "        self.embeddings = embeddings\n",
    "        self.index = faiss_index\n",
    "        self.tokenizer = tokenizer\n",
    "        self.model = model\n",
    "\n",
    "    def detect_intent(self, user_message: str) -> str:\n",
    "        return detect_intent(user_message)\n",
    "\n",
    "    def extract_entities(self, user_message: str):\n",
    "        return extract_entities(user_message)\n",
    "\n",
    "    def retrieve(self, query: str, k: int = 5, state_filter: str | None = None, deity_filter: str | None = None):\n",
    "        return search_temples(query, k=k, state_filter=state_filter, deity_filter=deity_filter)\n",
    "\n",
    "    def build_context(self, temple_records):\n",
    "        ctx_parts = []\n",
    "        for rec in temple_records:\n",
    "            raw = rec.get(\"raw\") or {}\n",
    "            sections = []\n",
    "            for key in (\"overview\", \"story\", \"visiting_guide\"):\n",
    "                val = raw.get(key)\n",
    "                if val:\n",
    "                    sections.append(str(val))\n",
    "            info_text = \" \".join(sections) or raw.get(\"text\") or rec.get(\"name\", \"\")\n",
    "            ctx_parts.append(\n",
    "                f\"Name: {rec.get('name', '')} | State: {rec.get('state', '')} | Deities: {', '.join(raw.get('deities', []) or [])} | Info: {info_text[:500]}\"\n",
    "            )\n",
    "        return \"\\n\".join(ctx_parts)\n",
    "\n",
    "    def generate(self, context_records, user_message: str) -> str:\n",
    "        context_text = self.build_context(context_records) if context_records else \"\"\n",
    "        return generate_answer(context_text or \"No specific context available.\", user_message)\n",
    "\n",
    "    def answer(self, user_message: str):\n",
    "        intent = self.detect_intent(user_message)\n",
    "        entities = self.extract_entities(user_message)\n",
    "\n",
    "        state_filter = entities.get(\"states\", [None])[0] if entities.get(\"states\") else None\n",
    "        deity_filter = entities.get(\"deities\", [None])[0] if entities.get(\"deities\") else None\n",
    "\n",
    "        if intent == \"TEMPLE_INFO\":\n",
    "            query_text = entities[\"temples\"][0] if entities.get(\"temples\") else user_message\n",
    "            hits = self.retrieve(query_text, k=5, state_filter=state_filter, deity_filter=deity_filter)\n",
    "            if not hits and entities.get(\"temples\"):\n",
    "                hits = self.retrieve(user_message, k=5, state_filter=state_filter, deity_filter=deity_filter)\n",
    "            if not hits:\n",
    "                reply = \"I couldn't find exact matches, but here are some similar temples: \"\n",
    "                alt_hits = self.retrieve(\"famous temples in India\", k=3)\n",
    "                if alt_hits:\n",
    "                    reply += \", \".join(h[\"name\"] for h in alt_hits)\n",
    "                else:\n",
    "                    reply = \"I couldn't find exact matches. Try mentioning a state or deity.\"\n",
    "            else:\n",
    "                reply = self.generate(hits, user_message)\n",
    "\n",
    "        elif intent == \"FIND_TEMPLES\":\n",
    "            hits = self.retrieve(user_message, k=5, state_filter=state_filter, deity_filter=deity_filter)\n",
    "            if not hits and (state_filter or deity_filter):\n",
    "                hits = self.retrieve(\"popular temples\", k=5)\n",
    "            if hits:\n",
    "                lines_out = []\n",
    "                for h in hits:\n",
    "                    raw = h.get(\"raw\") or {}\n",
    "                    deities = raw.get(\"deities\") or []\n",
    "                    line = f\"- {h['name']} ({h['state']})\"\n",
    "                    if deities:\n",
    "                        line += f\" | Deities: {', '.join(deities)}\"\n",
    "                    lines_out.append(line)\n",
    "                reply = \"Here are some temples you might like:\\n\" + \"\\n\".join(lines_out)\n",
    "            else:\n",
    "                reply = \"I couldn't find exact matches, but here are some similar temples\"\n",
    "\n",
    "        elif intent == \"PLAN_TRIP\":\n",
    "            days = entities.get(\"days\") or 2\n",
    "            hits = self.retrieve(user_message, k=max(days, 5), state_filter=state_filter, deity_filter=deity_filter)\n",
    "            if not hits and state_filter:\n",
    "                hits = self.retrieve(state_filter, k=max(days, 5))\n",
    "            if not hits:\n",
    "                alt_hits = self.retrieve(\"popular pilgrimage temples\", k=max(days, 3))\n",
    "                if alt_hits:\n",
    "                    hits = alt_hits\n",
    "                else:\n",
    "                    reply = \"I couldn't find exact matches, but here are some similar temples\"\n",
    "                    return {\"reply\": reply, \"intent\": intent, \"entities\": entities, \"used_temples\": []}\n",
    "            plan_lines = []\n",
    "            for i in range(days):\n",
    "                rec = hits[i % len(hits)] if hits else None\n",
    "                if rec:\n",
    "                    loc = (rec.get(\"raw\") or {}).get(\"location\") or (rec.get(\"raw\") or {}).get(\"city\") or rec.get(\"state\", \"\")\n",
    "                    plan_lines.append(f\"Day {i+1}: Visit {rec.get('name', 'a temple')} in {rec.get('state', '')} around {loc or 'the area'}\")\n",
    "                else:\n",
    "                    plan_lines.append(f\"Day {i+1}: Explore nearby temples or local sites.\")\n",
    "            reply = \"Here's a simple plan:\\n\" + \"\\n\".join(plan_lines)\n",
    "\n",
    "        elif intent == \"ITINERARY_COST\":\n",
    "            reply = (\n",
    "                \"A modest trip often costs around INR 2k-4k per day for stay, food, and local travel; \"\n",
    "                \"adjust upward for private transport or premium lodging. Prices vary by season and city.\"\n",
    "            )\n",
    "\n",
    "        elif intent == \"SMALL_TALK\":\n",
    "            reply = \"Hi there! I can help you discover temples, plan trips, or share details. What would you like to explore?\"\n",
    "\n",
    "        else:\n",
    "            reply = \"Could you clarify which temple, state, or deity you're interested in?\"\n",
    "\n",
    "        used = [h.get(\"name\", \"\") for h in hits] if \"hits\" in locals() else []\n",
    "        return {\n",
    "            \"reply\": reply,\n",
    "            \"intent\": intent,\n",
    "            \"entities\": entities,\n",
    "            \"used_temples\": used,\n",
    "        }\n",
    "\n",
    "\n",
    "bot = TempleChatbot(metadata, embeddings, index, tokenizer, flan_model)\n",
    "\n",
    "# 7) Interactive REPL (type exit/quit to stop)\n",
    "import sys\n",
    "if sys.stdin is None or not sys.stdin.isatty():\n",
    "    print(\"REPL skipped (no interactive stdin available).\")\n",
    "else:\n",
    "    while True:\n",
    "        user = input(\"You: \")\n",
    "        if user.lower() in [\"exit\", \"quit\"]:\n",
    "            break\n",
    "        print(bot.answer(user)[\"reply\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a4796cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T16:27:32.587599Z",
     "iopub.status.busy": "2025-11-30T16:27:32.587147Z",
     "iopub.status.idle": "2025-11-30T16:27:32.593559Z",
     "shell.execute_reply": "2025-11-30T16:27:32.592552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPL skipped (no interactive stdin available).\n"
     ]
    }
   ],
   "source": [
    "# 7) Interactive REPL (type exit/quit to stop)\n",
    "import sys\n",
    "if sys.stdin is None or not sys.stdin.isatty():\n",
    "    print(\"REPL skipped (no interactive stdin available).\")\n",
    "else:\n",
    "    while True:\n",
    "        user = input(\"You: \")\n",
    "        if user.lower() in [\"exit\", \"quit\"]:\n",
    "            break\n",
    "        result = bot.answer(user)\n",
    "        print(\"Bot:\", result[\"reply\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68f62e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from chatbot_backend import TempleChatbot, search_temples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f992ca13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi there! Im Agent Chaari, an Indian temple travel assistant. I can help you discover temples, plan simple trips, or share temple details. What would you like to explore?\n",
      "Im mainly designed to help with Indian temples and temple trips. Try asking about a temple, a state, or a deity.\n",
      "Here are some temples you might like:\n",
      "- Shore Temple (Tamil Nadu)\n",
      "- Sripuram Golden Temple (Tamil Nadu)\n",
      "- Srirangam Ranganathaswamy Temple, Srirangam (Tamil Nadu)\n",
      "- Tiruvannamalai Arunachaleswarar Temple, Tiruvannamalai (Tamil Nadu)\n",
      "- Ranganathaswamy Temple (Tamil Nadu)\n"
     ]
    }
   ],
   "source": [
    "# Quick sanity checks for chatbot backend\n",
    "bot = TempleChatbot(metadata, model, index, tokenizer, flan_model)\n",
    "print(bot.answer(\"Hi\")[\"reply\"])\n",
    "print(bot.answer(\"What is the capital of France?\")[\"reply\"])\n",
    "print(bot.answer(\"Temples in Tamil Nadu\")[\"reply\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8e26fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attribute retrieval smoke tests\n",
    "bot = TempleChatbot(metadata, model, index, tokenizer, flan_model)\n",
    "print(bot.answer(\"give me overview of Kashi Vishwanath Temple, Uttar Pradesh\")[\"reply\"])\n",
    "print(bot.answer(\"tell me the story of Kedarnath Temple\")[\"reply\"])\n",
    "print(bot.answer(\"visiting guide for Sripuram Golden Temple in Tamil Nadu\")[\"reply\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbca95eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, bot = load_chatbot_resources()\n",
    "\n",
    "test_queries = [\n",
    "    \"overview of Golden Temple\",\n",
    "    \"story of Kedarnath Temple\",\n",
    "    \"visiting guide for Tirumala, Andhra Pradesh\",\n",
    "    \"temples in Tamil Nadu\",\n",
    "]\n",
    "\n",
    "for q in test_queries:\n",
    "    res = bot.answer(q)\n",
    "    print(\"Q:\", q)\n",
    "    print(\"Intent:\", res[\"intent\"])\n",
    "    print(\"Reply:\", res[\"reply\"][:500], \"...\\n\")\n",
    "    print(\"Sections keys:\", list(res.get(\"sections\", {}).keys()))\n",
    "    print(\"=\" * 80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
